length(unique(cv_df$SubjectID))
cv_df$pmod <- cv_df$p*0.99 + 0.005
per_subj <- cv_df %>% group_by(width, SubjectID, continuum,block) %>% summarise(likelihood = sum(log(p_mod), na.rm = TRUE))
cv_df$p_mod <- cv_df$p*0.99 + 0.005
per_subj <- cv_df %>% group_by(width, SubjectID, continuum,block) %>% summarise(likelihood = sum(log(p_mod), na.rm = TRUE))
per_subj$id <- paste0(per_subj$continuum, "_", per_subj$block)
View(per_subj)
summary_by_width <- cv_df %>% group_by(width) %>% summarize(avg = mean(likelihood, na.rm = TRUE))
summary_by_width <- summary_df %>% group_by(width) %>% summarize(avg = mean(likelihood, na.rm = TRUE))
summary_df <- per_subj %>% group_by(width,continuum,block) %>% summarise(avg_p = mean(likelihood, na.rm = TRUE),
se = sd(likelihood, na.rm = TRUE)/sqrt(n()))
summary_by_width <- summary_df %>% group_by(width) %>% summarize(avg = mean(likelihood, na.rm = TRUE))
summary_by_width <- per_subj %>% group_by(width) %>% summarize(avg = mean(likelihood, na.rm = TRUE))
View(repos_df)
rm(list=ls())
filepath = '/home/eobrien/bde/Projects/Speech_contrasts/'
repos_df <- read.csv( paste0(filepath, "RDRPRepository_DATA_2018-01-02_1209.csv"))
registry_df<- read.csv( paste0(filepath, "RDRPRegistry_DATA_2018-01-02_1138.csv"))
master_df <- merge(repos_df, registry_df, by = "record_id")
file_list = list.files(path = "/home/eobrien/bde/Projects/Speech_contrasts/Results/Psychometrics/Raw")
file_str = str_extract_all(file_list, "[A-Za-z0-9]+")
subj_id <- character(length(file_list))
for (i in 1:length(file_list)){
subj_id[i] <- file_str[[i]][4]
}
subject = unique(subj_id)
rm(list=ls())
filepath = '/home/eobrien/bde/Projects/Speech_contrasts/'
library(tidyr)
library(stringr)
library(reshape2)
library(dplyr)
library(ggplot2)
rm(list=ls())
filepath = '/home/eobrien/bde/Projects/Speech_contrasts/'
repos_df <- read.csv( paste0(filepath, "RDRPRepository_DATA_2018-01-02_1209.csv"))
registry_df<- read.csv( paste0(filepath, "RDRPRegistry_DATA_2018-01-02_1138.csv"))
master_df <- merge(repos_df, registry_df, by = "record_id")
file_list = list.files(path = "/home/eobrien/bde/Projects/Speech_contrasts/Results/Psychometrics/Raw")
file_str = str_extract_all(file_list, "[A-Za-z0-9]+")
subj_id <- character(length(file_list))
for (i in 1:length(file_list)){
subj_id[i] <- file_str[[i]][4]
}
subject = unique(subj_id)
subj_record_id <- master_df %>% filter(sid.x %in% subject) %>% select(record_id)
subject_df <- master_df %>% filter(record_id %in% subj_record_id$record_id)
names <- colnames(master_df)
wj_cols <- names[grepl('wj', names)]
all_reading_tests <- c(wj_cols)
reading_df <- subject_df[c("record_id","dys_dx","adhd_dx","brain_injury","aud_dis", "psych_dx","wj_brs","wasi_fs2" )]
reading_df <- reading_df[!duplicated(reading_df),]
reading_df <- reading_df %>% group_by(record_id) %>% summarise_all(funs(mean(as.numeric(.), na.rm=TRUE)))
bio_df <- subject_df[c("sid.x","dob","record_id")]
bio_df[bio_df==""] <- NA
bio_df <- na.omit(bio_df)
filepath = '/home/eobrien/bde/Projects/Speech_contrasts/Results/Psychometrics/Fit_Uniform_Slope'
filelist = list.files(path = filepath,pattern = ".*.csv")
full_file_list <- paste0(filepath, '/',filelist)
pm <- data.frame()
for (i in 1:length(full_file_list)){
data<- read.csv(paste0(full_file_list[i]))
pm <- rbind(pm, data)
}
colnames(pm)[1] <- "sid.x"
filepath = '/home/eobrien/bde/Projects/Speech_contrasts/Results/CV_Leave_Out'
filelist = list.files(path = filepath,pattern = ".*.csv")
full_file_list <- paste0(filepath, '/',filelist)
cvpm <- data.frame()
for (i in 1:length(full_file_list)){
data<- read.csv(paste0(full_file_list[i]))
if (grepl("Ba_Da", full_file_list[i])){
data$continuum = "Ba-Da"
}
else{
data$continuum = "Sa-Sha"
data$p <- 1 - data$p}
cvpm <- rbind(cvpm, data)}
timestamp = numeric(length(subject))
filepath = '/home/eobrien/bde/Projects/Speech_contrasts/Results/'
for (i in 1:length(subject)){
con <- file(paste0(filepath, "/Raw/", subject[i], "_categorization_Ba_Da_1.txt"))
timestamp[i] <- readLines(con,n=1)
close(con)
}
timestamp_df = data.frame(psych_date = timestamp,
sid.x = subject)
vars <- colsplit(timestamp_df$psych_date, ",", c("date","time"))
timestamp_df$psych_date <- vars$date
bio_df <- merge(bio_df, timestamp_df)
bio_df$dob <- as.POSIXct(bio_df$dob, format="%Y-%m-%d")
bio_df$psych_date <- as.POSIXct(bio_df$psych_date, format="%Y-%m-%d")
bio_df$age_at_testing <- as.numeric(difftime(bio_df$psych_date,bio_df$dob,units="weeks")/52.25)
master_df <- merge(bio_df, pm)
master_df <- merge(master_df, reading_df)
use_df <- subset(master_df, psych_date >= "2017-08-15")
use_df <- subset(use_df, age_at_testing >= 8 & age_at_testing <13)
use_df <- subset(use_df, aud_dis == 0)
use_df <- subset(use_df, wasi_fs2 >= 70)
use_df <- subset(use_df, threshold >= 1 & threshold <= 7)
use_df <- subset(use_df, !(sid.x %in% c("IB701","KB630","IB706","IB263","HB656","HB213","IB319","HB742","GB727")))
sub_df <- subset(use_df, sound2 != "Single")
sub_df <- mutate(sub_df, continuum = ifelse(sound2 %in% c("Sa","Sha"), "Sa-Sha", "Ba-Da"))
sub_df$id <- paste0(sub_df$sid.x, "_", sub_df$sound2)
ABX_sum_big <- sub_df %>% group_by(sid.x,width,continuum) %>% summarise(mean_slope = mean(slope),
mean_end = mean((lapse+guess)/2),
wj_brs = unique(wj_brs),
mean_residuals = mean(residuals),
mean_deviance = mean(deviance))
sid_list <- unique(use_df$sid.x)
cv_df <- subset(cvpm, SubjectID %in% sid_list)
cv_df$p_mod <- use_df$p*0.99 + 0.005
cv_df$p_mod <- cv_df$p*0.99 + 0.005
per_subj <- cv_df %>% group_by(width, SubjectID, continuum,block) %>% summarise(likelihood = sum(log(p_mod), na.rm = TRUE))
summary_by_width <- per_subj %>% group_by(width) %>% summarise(avg_l = mean(likelihood, na.rm = TRUE),
se_l = sd(likelihood, na.rm = TRUE)/sqrt(n()))
summary_by_width
px1b <- ggplot(summary_by_width, aes(width, avg_l)) +
geom_point(size = 4) +
geom_line(size = 2)+
xlab("Asymptotic Prior Width") +
ylab("Mean Prediction Likelihood")+
theme(legend.position = c(0.8,0.1),
legend.background = element_rect(fill = alpha("white",0.4), colour = NA),
text = element_text(size=18))
px1b
px3 <- ggplot(summary_by_width, aes(width, avg_l)) +
geom_point(size = 4) +
geom_line(size = 2)+
xlab("Asymptotic Prior Width") +
ylab("Mean Prediction Likelihood")+
theme(legend.position = c(0.8,0.1),
legend.background = element_rect(fill = alpha("white",0.4), colour = NA),
text = element_text(size=18))
px3
bootstrap_correlation <- function(ABX_sum){
r2slope <- vector("numeric", 10L)
r2end <- vector("numeric", 10L)
residuals <- vector("numeric", 10L)
deviance <- vector("numeric", 10L)
for (i in 1:length(unique(ABX_sum$width))){
this_width = unique(ABX_sum$width)[i]
lmfit <- lm(mean_slope ~ wj_brs, subset(ABX_sum, width == this_width))
r2slope[i] <- sqrt(summary(lmfit)$r.squared)
# Same thing for the endpoints
lmfit <- lm(mean_end ~ wj_brs, subset(ABX_sum, width == this_width))
r2end[i] <- sqrt(summary(lmfit)$r.squared)
# Get the summed deviance
sub <- subset(ABX_sum, width == this_width)
deviance[i] <- sum(sub$mean_deviance)
residuals[i] <- sum(sub$mean_residuals)
}
################### Bootstrap the correlation to compute standard errors ######################################
nsim <- 1000
rslope_sim <- vector("numeric", 1000L)
pslope_sim <- vector("numeric", 1000L)
rend_sim <- vector("numeric", 1000L)
pend_sim <- vector("numeric", 1000L)
mu_slope <- vector("numeric", 10L)
mu_p_slope <- vector("numeric", 10L)
mu_p_end <- vector("numeric", 10L)
mu_end <- vector("numeric", 10L)
se_slope <- vector("numeric", 10L)
se_end <- vector("numeric", 10L)
for (h in 1:length(unique(ABX_sum$width))){
sub <- subset(ABX_sum, width == unique(ABX_sum$width)[h])
for (i in 1:nsim){
sampler <- sub[sample(nrow(sub), replace = TRUE), ]
lmfit <- lm(mean_slope ~ wj_brs, sampler)
rslope_sim[i] <- sqrt(summary(lmfit)$r.squared)
pslope_sim[i] <- anova(lmfit)$'Pr(>F)'[1]
# Same thing for the endpoints
lmfit <- lm(mean_end ~ wj_brs, sampler)
rend_sim[i] <- sqrt(summary(lmfit)$r.squared)
pend_sim[i] <- anova(lmfit)$'Pr(>F)'[1]
}
mu_slope[h] <- mean(rslope_sim)
mu_end[h] <- mean(rend_sim)
mu_p_slope[h] <- mean(pslope_sim)
mu_p_end[h] <- mean(pend_sim)
se_slope[h] <- sd(rslope_sim)
se_end[h] <- sd(rend_sim)
}
mu_end[1] <- 0
se_end[1] <- 0
mu_p_end[1] <-1
dfslope <- data.frame(Correlation = mu_slope, SE = se_slope, p = mu_p_slope, Type = "Slope", Width =  unique(ABX_sum$width))
dfasym <- data.frame(Correlation = mu_end, SE = se_end, p = mu_p_end,Type = "Asymptote", Width = unique(ABX_sum$width))
df <- rbind(dfslope, dfasym)
df$is_significant = df$p < 0.05
return(df)}
df1 <- bootstrap_correlation(subset(ABX_sum_big, continuum == "Ba-Da"))
df2 <- bootstrap_correlation(subset(ABX_sum_big, continuum == "Sa-Sha"))
px1 <- ggplot(df1, aes(Width, Correlation, group = Type, colour = Type)) +
geom_point(size=3, aes(shape = is_significant))+
scale_shape_manual(values = c(1,16))+
geom_smooth(se = FALSE)+
geom_ribbon(aes(ymin=Correlation - SE, ymax= Correlation + SE, fill = Type),alpha = 0.2,size = 0.1)+
scale_fill_manual("Parameter",values=c("gray10","darkseagreen"))+
theme_bw()+
scale_color_manual("Parameter",values=c("gray7","darkseagreen"))+
xlab("Asymptotic Prior Width")+
ylab("Correlation with WJ-BRS")+
ggtitle("/ba/-/da/")+
theme(legend.position = c(0.8,0.1),
legend.background = element_rect(fill = alpha("white",0.4), colour = NA),
text = element_text(size=18))+
guides(fill=guide_legend(title="Parameter"),
shape = FALSE)
px1
px2 <- ggplot(df2, aes(Width, Correlation, group = Type, colour = Type)) +
geom_point(size=3, aes(shape = is_significant))+
scale_shape_manual(values = c(1,16))+
geom_smooth(se = FALSE)+
geom_ribbon(aes(ymin=Correlation - SE, ymax= Correlation + SE, fill = Type),alpha = 0.2,size = 0.1)+
scale_fill_manual("Parameter",values=c("gray10","darkseagreen"))+
theme_bw()+
scale_color_manual("Parameter",values=c("gray7","darkseagreen"))+
xlab("Asymptotic Prior Width")+
ylab("Correlation with WJ-BRS")+
ggtitle('/sa/-/sha')+
theme(legend.position = c(0.8,0.1),
legend.background = element_rect(fill = alpha("white",0.4), colour = NA),
text = element_text(size=18))+
guides(fill=guide_legend(title="Parameter"),
shape = FALSE)
px2
px3 <- ggplot(summary_by_width, aes(width, avg_l)) +
geom_point(size = 4) +
geom_line(size = 2)+
xlab("Asymptotic Prior Width") +
ylab("Mean Prediction Likelihood")+
theme(legend.position = c(0.8,0.1),
legend.background = element_rect(fill = alpha("white",0.4), colour = NA),
text = element_text(size=18))
px3
px <- grid.arrange(myplot1, myplot2, myplot3, nrow = 1)
library(grid)
library(gridExtra)
myplot1 <- arrangeGrob(px1, top = textGrob("A", x = unit(0.1, "npc")
, y = unit(0.5, "npc"), just=c("left","top"),
gp=gpar(col="black", fontsize=54)))
myplot2 <- arrangeGrob(px2, top = textGrob("B", x = unit(0.1, "npc")
, y = unit(0.5, "npc"), just=c("left","top"),
gp=gpar(col="black", fontsize=54)))
myplot3 <- arrangeGrob(px3, top = textGrob("C", x = unit(0.1, "npc")
, y  = unit(0.5, "npc"), just=c("left","top"),
gp=gpar(col="black", fontsize=54)))
px <- grid.arrange(myplot1, myplot2, myplot3, nrow = 1)
library(tidyr)
library(stringr)
library(reshape2)
library(dplyr)
library(ggplot2)
library(grid)
library(gridExtra)
rm(list=ls())
filepath = '/home/eobrien/bde/Projects/Speech_contrasts/'
repos_df <- read.csv( paste0(filepath, "RDRPRepository_DATA_2018-01-02_1209.csv"))
registry_df<- read.csv( paste0(filepath, "RDRPRegistry_DATA_2018-01-02_1138.csv"))
master_df <- merge(repos_df, registry_df, by = "record_id")
file_list = list.files(path = "/home/eobrien/bde/Projects/Speech_contrasts/Results/Psychometrics/Raw")
file_str = str_extract_all(file_list, "[A-Za-z0-9]+")
subj_id <- character(length(file_list))
for (i in 1:length(file_list)){
subj_id[i] <- file_str[[i]][4]
}
subject = unique(subj_id)
subj_record_id <- master_df %>% filter(sid.x %in% subject) %>% select(record_id)
subject_df <- master_df %>% filter(record_id %in% subj_record_id$record_id)
names <- colnames(master_df)
wj_cols <- names[grepl('wj', names)]
all_reading_tests <- c(wj_cols)
reading_df <- subject_df[c("record_id","dys_dx","adhd_dx","brain_injury","aud_dis", "psych_dx","wj_brs","wasi_fs2" )]
reading_df <- reading_df[!duplicated(reading_df),]
reading_df <- reading_df %>% group_by(record_id) %>% summarise_all(funs(mean(as.numeric(.), na.rm=TRUE)))
bio_df <- subject_df[c("sid.x","dob","record_id")]
bio_df[bio_df==""] <- NA
bio_df <- na.omit(bio_df)
filepath = '/home/eobrien/bde/Projects/Speech_contrasts/Results/Psychometrics/Fit_Uniform_Slope'
filelist = list.files(path = filepath,pattern = ".*.csv")
full_file_list <- paste0(filepath, '/',filelist)
pm <- data.frame()
for (i in 1:length(full_file_list)){
data<- read.csv(paste0(full_file_list[i]))
pm <- rbind(pm, data)
}
colnames(pm)[1] <- "sid.x"
filepath = '/home/eobrien/bde/Projects/Speech_contrasts/Results/CV_Leave_Out'
filelist = list.files(path = filepath,pattern = ".*.csv")
full_file_list <- paste0(filepath, '/',filelist)
cvpm <- data.frame()
for (i in 1:length(full_file_list)){
data<- read.csv(paste0(full_file_list[i]))
if (grepl("Ba_Da", full_file_list[i])){
data$continuum = "Ba-Da"
}
else{
data$continuum = "Sa-Sha"
data$p <- 1 - data$p}
cvpm <- rbind(cvpm, data)}
timestamp = numeric(length(subject))
filepath = '/home/eobrien/bde/Projects/Speech_contrasts/Results/'
for (i in 1:length(subject)){
con <- file(paste0(filepath, "/Raw/", subject[i], "_categorization_Ba_Da_1.txt"))
timestamp[i] <- readLines(con,n=1)
close(con)
}
timestamp_df = data.frame(psych_date = timestamp,
sid.x = subject)
vars <- colsplit(timestamp_df$psych_date, ",", c("date","time"))
timestamp_df$psych_date <- vars$date
bio_df <- merge(bio_df, timestamp_df)
bio_df$dob <- as.POSIXct(bio_df$dob, format="%Y-%m-%d")
bio_df$psych_date <- as.POSIXct(bio_df$psych_date, format="%Y-%m-%d")
bio_df$age_at_testing <- as.numeric(difftime(bio_df$psych_date,bio_df$dob,units="weeks")/52.25)
master_df <- merge(bio_df, pm)
master_df <- merge(master_df, reading_df)
use_df <- subset(master_df, psych_date >= "2017-08-15")
use_df <- subset(use_df, age_at_testing >= 8 & age_at_testing <13)
use_df <- subset(use_df, aud_dis == 0)
use_df <- subset(use_df, wasi_fs2 >= 70)
use_df <- subset(use_df, threshold >= 1 & threshold <= 7)
use_df <- subset(use_df, !(sid.x %in% c("IB701","KB630","IB706","IB263","HB656","HB213","IB319","HB742","GB727")))
sub_df <- subset(use_df, sound2 != "Single")
sub_df <- mutate(sub_df, continuum = ifelse(sound2 %in% c("Sa","Sha"), "Sa-Sha", "Ba-Da"))
sub_df$id <- paste0(sub_df$sid.x, "_", sub_df$sound2)
ABX_sum_big <- sub_df %>% group_by(sid.x,width,continuum) %>% summarise(mean_slope = mean(slope),
mean_end = mean((lapse+guess)/2),
wj_brs = unique(wj_brs),
mean_residuals = mean(residuals),
mean_deviance = mean(deviance))
bootstrap_correlation <- function(ABX_sum){
r2slope <- vector("numeric", 10L)
r2end <- vector("numeric", 10L)
residuals <- vector("numeric", 10L)
deviance <- vector("numeric", 10L)
for (i in 1:length(unique(ABX_sum$width))){
this_width = unique(ABX_sum$width)[i]
lmfit <- lm(mean_slope ~ wj_brs, subset(ABX_sum, width == this_width))
r2slope[i] <- sqrt(summary(lmfit)$r.squared)
# Same thing for the endpoints
lmfit <- lm(mean_end ~ wj_brs, subset(ABX_sum, width == this_width))
r2end[i] <- sqrt(summary(lmfit)$r.squared)
# Get the summed deviance
sub <- subset(ABX_sum, width == this_width)
deviance[i] <- sum(sub$mean_deviance)
residuals[i] <- sum(sub$mean_residuals)
}
################### Bootstrap the correlation to compute standard errors ######################################
nsim <- 10000
rslope_sim <- vector("numeric", 1000L)
pslope_sim <- vector("numeric", 1000L)
rend_sim <- vector("numeric", 1000L)
pend_sim <- vector("numeric", 1000L)
mu_slope <- vector("numeric", 10L)
mu_p_slope <- vector("numeric", 10L)
mu_p_end <- vector("numeric", 10L)
mu_end <- vector("numeric", 10L)
se_slope <- vector("numeric", 10L)
se_end <- vector("numeric", 10L)
for (h in 1:length(unique(ABX_sum$width))){
sub <- subset(ABX_sum, width == unique(ABX_sum$width)[h])
for (i in 1:nsim){
sampler <- sub[sample(nrow(sub), replace = TRUE), ]
lmfit <- lm(mean_slope ~ wj_brs, sampler)
rslope_sim[i] <- sqrt(summary(lmfit)$r.squared)
pslope_sim[i] <- anova(lmfit)$'Pr(>F)'[1]
# Same thing for the endpoints
lmfit <- lm(mean_end ~ wj_brs, sampler)
rend_sim[i] <- sqrt(summary(lmfit)$r.squared)
pend_sim[i] <- anova(lmfit)$'Pr(>F)'[1]
}
mu_slope[h] <- mean(rslope_sim)
mu_end[h] <- mean(rend_sim)
mu_p_slope[h] <- mean(pslope_sim)
mu_p_end[h] <- mean(pend_sim)
se_slope[h] <- sd(rslope_sim)
se_end[h] <- sd(rend_sim)
}
mu_end[1] <- 0
se_end[1] <- 0
mu_p_end[1] <-1
dfslope <- data.frame(Correlation = mu_slope, SE = se_slope, p = mu_p_slope, Type = "Slope", Width =  unique(ABX_sum$width))
dfasym <- data.frame(Correlation = mu_end, SE = se_end, p = mu_p_end,Type = "Asymptote", Width = unique(ABX_sum$width))
df <- rbind(dfslope, dfasym)
df$is_significant = df$p < 0.05
return(df)}
df1 <- bootstrap_correlation(subset(ABX_sum_big, continuum == "Ba-Da"))
df2 <- bootstrap_correlation(subset(ABX_sum_big, continuum == "Sa-Sha"))
px1 <- ggplot(df1, aes(Width, Correlation, group = Type, colour = Type)) +
geom_point(size=3, aes(shape = is_significant))+
scale_shape_manual(values = c(1,16))+
geom_smooth(se = FALSE)+
geom_ribbon(aes(ymin=Correlation - SE, ymax= Correlation + SE, fill = Type),alpha = 0.2,size = 0.1)+
scale_fill_manual("Parameter",values=c("gray10","darkseagreen"))+
theme_bw()+
scale_color_manual("Parameter",values=c("gray7","darkseagreen"))+
xlab("Asymptotic Prior Width")+
ylab("Correlation with WJ-BRS")+
ggtitle("/ba/-/da/")+
theme(legend.position = c(0.8,0.1),
legend.background = element_rect(fill = alpha("white",0.4), colour = NA),
text = element_text(size=24),
plot.margin = unit(c(1,1,1,2),"lines"))+
guides(fill=guide_legend(title="Parameter"),
shape = FALSE)
px1
px2 <- ggplot(df2, aes(Width, Correlation, group = Type, colour = Type)) +
geom_point(size=3, aes(shape = is_significant))+
scale_shape_manual(values = c(1,16))+
geom_smooth(se = FALSE)+
geom_ribbon(aes(ymin=Correlation - SE, ymax= Correlation + SE, fill = Type),alpha = 0.2,size = 0.1)+
scale_fill_manual("Parameter",values=c("gray10","darkseagreen"))+
theme_bw()+
scale_color_manual("Parameter",values=c("gray7","darkseagreen"))+
xlab("Asymptotic Prior Width")+
ylab("Correlation with WJ-BRS")+
ggtitle('/sa/-/sha')+
theme(legend.position = c(0.8,0.1),
legend.background = element_rect(fill = alpha("white",0.4), colour = NA),
text = element_text(size=24),
plot.margin = unit(c(1,1,1,2),"lines"))+
guides(fill=guide_legend(title="Parameter"),
shape = FALSE)
sid_list <- unique(use_df$sid.x)
cv_df <- subset(cvpm, SubjectID %in% sid_list)
cv_df$p_mod <- cv_df$p*0.99 + 0.005
per_subj <- cv_df %>% group_by(width, SubjectID, continuum,block) %>% summarise(likelihood = sum(log(p_mod), na.rm = TRUE))
summary_by_width <- per_subj %>% group_by(width) %>% summarise(avg_l = mean(likelihood, na.rm = TRUE),
se_l = sd(likelihood, na.rm = TRUE)/sqrt(n()))
summary <- cv_df %>% group_by(width) %>% summarise(avg_l = median(p, na.rm = TRUE))
px3 <- ggplot(summary, aes(width, avg_l)) +
geom_point(size = 4) +
geom_line(size = 2)+
xlab("Asymptotic Prior Width") +
ylab("Median Prediction Likelihood")+
ggtitle("")+
theme_bw() +
theme(text = element_text(size=24),
plot.margin = unit(c(1,1,1,2),"lines"))
px3
px1 <- ggplot(df1, aes(Width, Correlation, group = Type, colour = Type)) +
geom_point(size=4, aes(shape = is_significant))+
scale_shape_manual(values = c(1,16))+
geom_smooth(se = FALSE)+
geom_ribbon(aes(ymin=Correlation - SE, ymax= Correlation + SE, fill = Type),alpha = 0.2,size = 0.1)+
scale_fill_manual("Parameter",values=c("gray10","darkseagreen"))+
theme_bw()+
scale_color_manual("Parameter",values=c("gray7","darkseagreen"))+
xlab("Asymptotic Prior Width")+
ylab("Correlation with WJ-BRS")+
ggtitle("/ba/-/da/")+
theme(legend.position = c(0.8,0.1),
legend.background = element_rect(fill = alpha("white",0.4), colour = NA),
text = element_text(size=24),
plot.margin = unit(c(1,1,1,2),"lines"))+
guides(fill=guide_legend(title="Parameter"),
shape = FALSE)
px1
px2 <- ggplot(df2, aes(Width, Correlation, group = Type, colour = Type)) +
geom_point(size=4, aes(shape = is_significant))+
scale_shape_manual(values = c(1,16))+
geom_smooth(se = FALSE)+
geom_ribbon(aes(ymin=Correlation - SE, ymax= Correlation + SE, fill = Type),alpha = 0.2,size = 0.1)+
scale_fill_manual("Parameter",values=c("gray10","darkseagreen"))+
theme_bw()+
scale_color_manual("Parameter",values=c("gray7","darkseagreen"))+
xlab("Asymptotic Prior Width")+
ylab("Correlation with WJ-BRS")+
ggtitle('/sa/-/sha')+
theme(legend.position = c(0.8,0.1),
legend.background = element_rect(fill = alpha("white",0.4), colour = NA),
text = element_text(size=24),
plot.margin = unit(c(1,1,1,2),"lines"))+
guides(fill=guide_legend(title="Parameter"),
shape = FALSE)
px2
sid_list <- unique(use_df$sid.x)
cv_df <- subset(cvpm, SubjectID %in% sid_list)
cv_df$p_mod <- cv_df$p*0.99 + 0.005
per_subj <- cv_df %>% group_by(width, SubjectID, continuum,block) %>% summarise(likelihood = sum(log(p_mod), na.rm = TRUE))
summary_by_width <- per_subj %>% group_by(width) %>% summarise(avg_l = mean(likelihood, na.rm = TRUE),
se_l = sd(likelihood, na.rm = TRUE)/sqrt(n()))
summary <- cv_df %>% group_by(width) %>% summarise(avg_l = median(p, na.rm = TRUE))
px3 <- ggplot(summary, aes(width, avg_l)) +
geom_point(size = 4) +
geom_line(size = 2)+
xlab("Asymptotic Prior Width") +
ylab("Median Prediction Likelihood")+
ggtitle("")+
theme_bw() +
theme(text = element_text(size=24),
plot.margin = unit(c(1,1,1,2),"lines"))
px3
myplot1 <- arrangeGrob(px1, top = textGrob("A", x = unit(0, "npc")
, y = unit(0.5, "npc"), just=c("left","top"),
gp=gpar(col="black", fontsize=54)))
myplot2 <- arrangeGrob(px2, top = textGrob("B", x = unit(0, "npc")
, y = unit(0.5, "npc"), just=c("left","top"),
gp=gpar(col="black", fontsize=54)))
myplot3 <- arrangeGrob(px3, top = textGrob("C", x = unit(0, "npc")
, y  = unit(0.5, "npc"), just=c("left","top"),
gp=gpar(col="black", fontsize=54)))
px <- grid.arrange(myplot1, myplot2, myplot3, nrow = 1)
ggsave(paste0("./Images/","Figure_7.eps"), px, device = cairo_ps, width = 20, height = 10)
ggsave(paste0("./Images/","Figure_7.png"), px,  width = 19, height = 10)
ggsave(paste0("./Images/","Figure_7.tiff"), px,  width = 19, height = 10, dpi = 300)
setwd("/home/eobrien/bde/Projects/Speech_contrasts/Results")
ggsave(paste0("./Images/","Figure_7.eps"), px, device = cairo_ps, width = 20, height = 10)
ggsave(paste0("./Images/","Figure_7.png"), px,  width = 19, height = 10)
ggsave(paste0("./Images/","Figure_7.tiff"), px,  width = 19, height = 10, dpi = 300)
